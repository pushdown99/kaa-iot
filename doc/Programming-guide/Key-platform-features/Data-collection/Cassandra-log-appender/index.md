---
layout: page
title: Cassandra log appender
permalink: /:path/
nav: /:path/Programming-guide/Key-platform-features/Data-collection/Cassandra-log-appender
sort_idx: 10
---

{% include variables.md %}

* TOC
{:toc}

The Cassandra log appender is responsible for transferring logs from the Operations service to the Cassandra database.

# Creating Cassandra log appender with Admin UI

The easiest way to create a Cassandra log appender for your application is by using Admin UI.

To create a log appender do the following:

1. In the **Log appenders** window, click **Add log appender**.
2. Enter the log appender name and description, select the minimum and maximum supported schema version, select necessary log metadata fields.
3. Set the log appender type to _Cassandra_. <br/>
![Create cassandra log appender](attach/create-cassandra-log-appender-admin-ui.png)
4. Fill in the Cassandra log appender [Configuration](#configuration) form. <br/>
![Cassandra log appender configuration](attach/cassandra-log-appender-config1.png) <br/>
![](attach/cassandra-log-appender-config2.png) <br/>
![](attach/cassandra-log-appender-config3.png) <br/>
5. Click **Add** button. Log appender is ready and operational at this point.


# Creating Cassandra log appender with Admin REST API

It is also possible to create a Cassandra log appender instance by using
[Admin REST API]({{root_url}}Programming-guide/Server-REST-APIs/#!/Logging/editLogAppender).
The following example illustrates how to create the Cassandra log appender via Admin REST API.

## Configuration

The Cassandra log appender configuration must match to
[this]({{github_url}}server/appenders/cassandra-appender/src/main/avro/cassandra-appender-config.avsc) Avro schema.

* **Cassandra nodes** - list of Cassandra hosts.
* **Authentication credentials** - credentials used to authenticate on Cassandra cluster.
* **Keyspace name** – Cassandra keyspace used to prefix the data table.
* **Table name pattern** – pattern used to create table name (for example: **logs_$app_token** adds the application token at the end of the table name).
* **Column Mapping** - section that handles data mapping configuration. It can map specific log data to appropriate columns.
* **Clustering** - section that handles clustering key configuration.

|Type           |Example value                                                                  |Example column type|Description                                                                                                            |
|---------------|-------------------------------------------------------------------------------|-------------------|-----------------------------------------------------------------------------------------------------------------------|
|HEADER_FIELD   |endpointKeyHash, applicationToken, headerVersion,timestamp, logSchemaVersion   |TEXT               |Maps a header variable to the specified column                                                                         |
|EVENT_FIELD    |telemetry                                                                      |DOUBLE             |Maps a log schema field to the specified column                                                                        |
|CLIENT_FIELD   |clientField                                                                    |TEXT               |Maps a client-side endpoint profile field to the specified column                                                      |
|SERVER_FIELD   |serverField                                                                    |TEXT               |Maps a server-side endpoint profile field to the specified column                                                      |
|${TYPE}_JSON   |                                                                               |TEXT               |Maps one of the fields listed above as a corresponding JSON                                                            |
|${TYPE}_BINARY |                                                                               |BLOB               |Maps one of the fields listed above in binary format                                                                   |
|UUID           |                                                                               |UUID               |Maps a UUID generated by Kaa to the specified field                                                                    |
|TS             |yyyy-MM-dd-'Time:'HH:mm:ss.SS                                                  |TEXT               |Maps a timestamp generated by Kaa to the specified field. Timestamp pattern is handled by java.text.SimpleDateFormat   |

Any field can be made a partition and/or clustering key with using corresponding checkboxes.

Key clustering is configured by **Clustering** section, by adding column names and setting their order (**DESC** or **ASC**).

>**NOTE:**  
> Cassandra driver settings can be specified in log appender configuration. Consult the official 
[documentation](http://docs.datastax.com/en/landing_page/doc/landing_page/current.html) for reference.

An example configuration that matches to previously introduced Avro schema is as below:

```json
{
    "cassandraServers":[
        {
            "host":"localhost",
            "port ":9042
        }
    ],
    "cassandraCredential":{
        "org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraCredential ":{
            "user":"user",
            "password":"password"
        }
    },
    "keySpace":"kaa",
    "tableNamePattern":"logs_$app_token_$config_hash",
    "columnMapping":[
        {
            "type ":"HEADER_FIELD",
            "value ":{
                "string ":"applicationToken"
            },
            "columnName":"application_token",
            "columnType":"TEXT ",
            "partitionKey ":false,
            "clusteringKey ":false
        },
        {
            "type":"EVENT_FIELD",
            "value ":{
                "string ":"message"
            },
            "columnName":"message",
            "columnType ":"TEXT ",
            "partitionKey ":false,
            "clusteringKey ":false
        },
        {
            "type":"UUID",
            "value ":{
                "string ":"id "
            },
            "columnName":"id",
            "columnType":"UUID",
            "partitionKey":true,
            "clusteringKey":false
        }
    ],
    "clusteringMapping":[

    ],
    "cassandraBatchType":{
        "org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraBatchType":"UNLOGGED"
    },
    "cassandraSocketOption":null,
    "executorThreadPoolSize ":1,
    "callbackThreadPoolSize ":2,
    "dataTTL ":0,
    "cassandraWriteConsistencyLevel ":{
        "org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraWriteConsistencyLevel ":"ONE "
    },
    "cassandraCompression":{
        "org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraCompression ":"NONE "
    },
    "cassandraExecuteRequestType":{
        "org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraExecuteRequestType ":"SYNC "
    }
}
```


## Administration

The following Admin REST API call example illustrates how to create an instance of the Cassandra log appender.

```bash
curl -v -S -u devuser:devuser123 -X POST -H 'Content-Type: application/json' -d @cassandraLogAppender.json "http://localhost:8080/kaaAdmin/rest/api/logAppender" | python -mjson.tool
```

where file ```cassandraLogAppender.json``` contains following data:

```json
{
    "pluginClassName":"org.kaaproject.kaa.server.appenders.cassandra.appender.CassandraLogAppender",
    "pluginTypeName":"Cassandra",
    "applicationId":"5",
    "applicationToken":"82635305199158071549",
    "name":"Cassandra log appender",
    "description":"Sample Cassandra log appender",
    "headerStructure":[
        "KEYHASH",
        "VERSION",
        "TIMESTAMP",
        "TOKEN",
        "LSVERSION"
    ],
    "maxLogSchemaVersion":2147483647,
    "minLogSchemaVersion":1,
    "tenantId":"1",
    "jsonConfiguration":"{\"cassandraServers\":[{\"host\":\"localhost\",\"port\":9042}],\"cassandraCredential\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraCredential\":{\"user\":\"user\",\"password\":\"password\"}},\"keySpace\":\"kaa\",\"tableNamePattern\":\"logs_$app_token_$config_hash\",\"columnMapping\":[{\"type\":\"HEADER_FIELD\",\"value\":{\"string\":\"applicationToken\"},\"columnName\":\"application_token\",\"columnType\":\"TEXT\",\"partitionKey\":false,\"clusteringKey\":false},{\"type\":\"EVENT_FIELD\",\"value\":{\"string\":\"message\"},\"columnName\":\"message\",\"columnType\":\"TEXT\",\"partitionKey\":false,\"clusteringKey\":false},{\"type\":\"UUID\",\"value\":{\"string\":\"id\"},\"columnName\":\"id\",\"columnType\":\"UUID\",\"partitionKey\":true,\"clusteringKey\":false}],\"clusteringMapping\":[],\"cassandraBatchType\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraBatchType\":\"UNLOGGED\"},\"cassandraSocketOption\":null,\"executorThreadPoolSize\":1,\"callbackThreadPoolSize\":2,\"dataTTL\":0,\"cassandraWriteConsistencyLevel\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraWriteConsistencyLevel\":\"ONE\"},\"cassandraCompression\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraCompression\":\"NONE\"},\"cassandraExecuteRequestType\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraExecuteRequestType\":\"SYNC\"}}"
}
```

Example result:

```json
{
    "applicationId":"5",
    "applicationToken":"82635305199158071549",
    "confirmDelivery":true,
    "createdTime":1466055406507,
    "createdUsername":"devuser",
    "description":"Sample Cassandra log appender",
    "headerStructure":[
        "KEYHASH",
        "VERSION",
        "TIMESTAMP",
        "TOKEN",
        "LSVERSION"
    ],
    "id":"65548",
    "jsonConfiguration":"{\"cassandraServers\":[{\"host\":\"localhost\",\"port\":9042}],\"cassandraCredential\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraCredential\":{\"user\":\"user\",\"password\":\"password\"}},\"keySpace\":\"kaa\",\"tableNamePattern\":\"logs_$app_token_$config_hash\",\"columnMapping\":[{\"type\":\"HEADER_FIELD\",\"value\":{\"string\":\"applicationToken\"},\"columnName\":\"application_token\",\"columnType\":\"TEXT\",\"partitionKey\":false,\"clusteringKey\":false},{\"type\":\"EVENT_FIELD\",\"value\":{\"string\":\"message\"},\"columnName\":\"message\",\"columnType\":\"TEXT\",\"partitionKey\":false,\"clusteringKey\":false},{\"type\":\"UUID\",\"value\":{\"string\":\"id\"},\"columnName\":\"id\",\"columnType\":\"UUID\",\"partitionKey\":true,\"clusteringKey\":false}],\"clusteringMapping\":[],\"cassandraBatchType\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraBatchType\":\"UNLOGGED\"},\"cassandraSocketOption\":null,\"executorThreadPoolSize\":1,\"callbackThreadPoolSize\":2,\"dataTTL\":0,\"cassandraWriteConsistencyLevel\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraWriteConsistencyLevel\":\"ONE\"},\"cassandraCompression\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraCompression\":\"NONE\"},\"cassandraExecuteRequestType\":{\"org.kaaproject.kaa.server.appenders.cassandra.config.gen.CassandraExecuteRequestType\":\"SYNC\"}}",
    "maxLogSchemaVersion":2147483647,
    "minLogSchemaVersion":1,
    "name":"Cassandra log appender",
    "pluginClassName":"org.kaaproject.kaa.server.appenders.cassandra.appender.CassandraLogAppender",
    "pluginTypeName":"Cassandra",
    "tenantId":"1"
}
```

# Playing with Cassandra log appender

We'll use [Data collection demo](https://github.com/kaaproject/sample-apps/tree/master/datacollectiondemo/source) from Kaa Sandbox. Our example will send data
to Kaa and then persist it to Cassandra. Also, we'll do selection queries on persisted data.

We have next log schema:

```json
{
    "type":"record",
    "name":"Data",
    "namespace":"org.kaaproject.kaa.scheme.sample",
    "fields":[
        {
            "name":"temperature",
            "type":"int"
        },
        {
            "name":"timeStamp",
            "type":"long"
        }
    ],
    "displayName":"Logging scheme"
}
```

The following JSON example matches the previous schema.

```json
{
    "temperature":"28",
    "timeStamp":"1474366798"
}
```

1. Go to Data collection demos in Sandbox.
![Data collection demo in Sandbox](attach/data-collection-demo-in-sandbox.png)
2. Follow **Installation** instructions.
3. In the Admin UI follow to **Data collection demo** application.
4. Go to application's **Log appenders** configuration and add a new one.
![Add log appender](attach/data-collection-demo-application.png)
5. Enter name of the new appender (we'll use "Cassandra")
6. Add application token and Timestamp as Log metadata.
7. Select **Cassandra** appender type.
![Select Cassandra appender type](attach/cassandra-appender-type.png)
8. Add new node in the **Configuration** section (localhost:9042)
![Add new node](attach/configuration-section.png)
9. Add auth details if needed (for Sandbox it's empty)
10. Fill **Keyspace name**. "kaa" is used in this example, because it's already created on a Sandbox machine.
11. "logs_example" is used as the **Table name pattern**.
![Keyspace configuration](attach/configuration-section-keyspace.png)
12. The important part of configuration is **Column Mapping**:
![Column mapping](attach/column-mapping.png)
13. Other configuration:
![Other configuration](attach/other-configuration.png)
14. Click **Add** button on the top of the screen to create and deploy appender.
![Add button](attach/add-button.png)
15. Verify that newly created appender has appeared in list.
![Verify newly created appender](attach/verify-created-appender.png)
16. Use instructions from Sandbox to run Data collection demo application.
17. After this you should see something like below:

    ```bash
    Data collection demo started
    Received new sample period: 1
    Sampled temperature 28 1474366979
    Sampled temperature 31 1474366980
    Sampled temperature 32 1474366981
    Sampled temperature 30 1474366982
    Sampled temperature 28 1474366983
    ...
    ```

18. Let's verify that our logs have been persisted in Cassandra. Go to Sandbox VM and run next command to connect Cassandra:

    ```bash
    cqlsh
    ```

19. Then:

    ```bash
    SELECT * FROM kaa.logs_example;
    ```

20. You should observe similar output:

    ```bash
     date                         | timestamp_field | id                                   | application_token    | temperature_field
    ------------------------------+-----------------+--------------------------------------+----------------------+-------------------
     2016-09-20-Time:03:21:54.532 |      1474366979 | 8206acb5-e8b8-447f-bb61-757f25c154e9 | 65691512829156876532 |                28
     2016-09-20-Time:03:21:54.532 |      1474366980 | 193df613-3b0a-4498-b0fe-71ac8f8f964d | 65691512829156876532 |                31
     2016-09-20-Time:03:21:54.532 |      1474366981 | 26af685a-962a-4c6d-910d-3a08e66819cd | 65691512829156876532 |                32
     2016-09-20-Time:03:21:54.532 |      1474366982 | 6a276954-4adc-41c2-b3cb-bb09bf683b4b | 65691512829156876532 |                30
     2016-09-20-Time:03:21:54.532 |      1474366983 | 01e8408a-c2cd-451a-a402-ceafdd7c9df6 | 65691512829156876532 |                28
     ...
(5 rows)
    ```

If your output doesn't match above one, please follow our [troubleshooting guide]({{root_url}}Administration-guide/Troubleshooting).
